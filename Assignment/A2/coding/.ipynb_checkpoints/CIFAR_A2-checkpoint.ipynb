{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.305884\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 2.126789\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1.975413\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 2.339995\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 2.182638\n",
      "\n",
      "Test set: Average loss: 2.1010, Accuracy: 1972/10000 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.807204\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1.978794\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 2.142374\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.590717\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 2.279151\n",
      "\n",
      "Test set: Average loss: 2.1076, Accuracy: 1847/10000 (18%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.744625\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.998114\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 2.458207\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.056008\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 2.030291\n",
      "\n",
      "Test set: Average loss: 2.1227, Accuracy: 1790/10000 (18%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.068671\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 1.941327\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1.894700\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1.754293\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 2.499191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b67021cf183a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b67021cf183a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# use cross_entropy here, since there is no softmax function in my last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs_log_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "args_batch_size = 64\n",
    "args_test_batch_size = 1000\n",
    "args_epochs = 20\n",
    "args_lr = 0.001\n",
    "args_momentum = 0.9\n",
    "args_decay = 5e-4\n",
    "args_seed = 1\n",
    "args_log_interval = 2500\n",
    "args_no_cuda = False\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args_seed)\n",
    "if args_cuda:\n",
    "    torch.cuda.manual_seed(args_seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args_cuda else {}\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: define your network here \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0)\n",
    "        self.weight1 = self.conv1.weight.data.numpy()\n",
    "        self.features = nn.Sequential(\n",
    "            # 32 * 32 * 3, CIFAR\n",
    "            self.conv1,\n",
    "            # (32 - 5) / 1 + 1 = 28, 28 * 28 * 6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # (28 - 2) / 2 + 1 = 14, 14 * 14 * 6\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            # 14 - 5 + 1 = 10, 10 * 10 * 16\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 5 * 5 * 16\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        conv_features = self.features(x)\n",
    "        flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        fc = self.fc_layers(flatten)\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "        return fc\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_decay)\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list  = []\n",
    "valid_acc_list  = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # use cross_entropy here, since there is no softmax function in my last layer\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "        \n",
    "        loss_sum += loss.data\n",
    "        total += 1\n",
    "        \n",
    "    train_loss_list.append(loss_sum / total)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # preserve the accuracy for plot and comparison\n",
    "    test_loss_list.append(test_loss)\n",
    "    valid_acc_list.append(100. * correct / len(test_loader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, args_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.323506\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 2.142912\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 2.745064\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1.093693\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.813302\n",
      "\n",
      "Test set: Average loss: 1.4207, Accuracy: 4883/10000 (49%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.992471\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1.608712\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 1.194683\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.376128\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.102659\n",
      "\n",
      "Test set: Average loss: 1.3868, Accuracy: 5143/10000 (51%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.767755\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.568396\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 0.533004\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.075071\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.812473\n",
      "\n",
      "Test set: Average loss: 1.3111, Accuracy: 5327/10000 (53%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.459106\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.764019\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.789062\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1.127551\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 2.175224\n",
      "\n",
      "Test set: Average loss: 1.1799, Accuracy: 5817/10000 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.039875\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 1.265098\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.553946\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1.072184\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.716355\n",
      "\n",
      "Test set: Average loss: 1.1270, Accuracy: 6011/10000 (60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weight initialization\n",
    "\n",
    "\n",
    "# Training settings\n",
    "args_batch_size = 64\n",
    "args_test_batch_size = 1000\n",
    "args_epochs = 20\n",
    "args_lr = 0.001\n",
    "args_momentum = 0.9\n",
    "args_decay = 5e-4\n",
    "args_seed = 1\n",
    "args_log_interval = 2500\n",
    "args_no_cuda = False\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args_seed)\n",
    "if args_cuda:\n",
    "    torch.cuda.manual_seed(args_seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args_cuda else {}\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: define your network here \n",
    "            \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        # for visualize the filters in the first conv layer\n",
    "        self.weight1 = self.conv1.weight.data.numpy()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "#         self.features = nn.Sequential(\n",
    "#             # 32 * 32 * 3, CIFAR\n",
    "#             self.conv1,\n",
    "#             # (32 - 5) / 1 + 1 = 28, 28 * 28 * 6\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # (28 - 2) / 2 + 1 = 14, 14 * 14 * 6\n",
    "#             nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "#             # 14 - 5 + 1 = 10, 10 * 10 * 16\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # 5 * 5 * 16\n",
    "#         )  \n",
    "        \n",
    "#         self.fc_layers = nn.Sequential(\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(16 * 5 * 5, 120),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(120, 84),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(84, num_classes),\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        # conv_features = self.features(x)\n",
    "        # flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        # fc = self.fc_layers(flatten)\n",
    "        # probas = F.softmax(logits, dim=1)\n",
    "        # return fc\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_decay)\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list  = []\n",
    "valid_acc_list  = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # use cross_entropy here, since there is no softmax function in my last layer\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "        \n",
    "        loss_sum += loss.data\n",
    "        total += 1\n",
    "        \n",
    "    train_loss_list.append(loss_sum / total)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # preserve the accuracy for plot and comparison\n",
    "    test_loss_list.append(test_loss)\n",
    "    valid_acc_list.append(100. * correct / len(test_loader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, args_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ccc4ea71d69a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m232\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2677\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2679\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5679\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         if (self._A.dtype != np.uint8 and\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;31m# Note that the argument to `byteswap` is 'inplace',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the filters learned in the first convolutional layer\n",
    "plt.figure()\n",
    "plt.subplot(231)\n",
    "plt.imshow(model.weight1[0, ...].T)\n",
    "plt.subplot(232)\n",
    "plt.imshow(model.weight1[1, ...].T)\n",
    "plt.subplot(233)\n",
    "plt.imshow(model.weight1[2, ...].T)\n",
    "plt.subplot(234)\n",
    "plt.imshow(model.weight1[3, ...].T)\n",
    "plt.subplot(235)\n",
    "plt.imshow(model.weight1[4, ...].T)\n",
    "plt.subplot(236)\n",
    "plt.imshow(model.weight1[5, ...].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(np.arange(1, args_epochs+1), train_acc_list, label='Training')\n",
    "#plt.plot(np.arange(1, args_epochs+1), valid_acc_list, label='Validation')\n",
    "\n",
    "#plt.plot(np.arange(1, args_epochs+1), test_loss_list, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7",
   "language": "python",
   "name": "python-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
