{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.305884\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 2.126789\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 1.975413\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 2.339995\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 2.182638\n",
      "\n",
      "Test set: Average loss: 2.1010, Accuracy: 1972/10000 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.807204\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1.978794\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 2.142374\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.590717\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 2.279151\n",
      "\n",
      "Test set: Average loss: 2.1076, Accuracy: 1847/10000 (18%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.744625\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.998114\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 2.458207\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.056008\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 2.030291\n",
      "\n",
      "Test set: Average loss: 2.1227, Accuracy: 1790/10000 (18%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.068671\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 1.941327\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 1.894700\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1.754293\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 2.499191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b67021cf183a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b67021cf183a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# use cross_entropy here, since there is no softmax function in my last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs_log_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "args_batch_size = 64\n",
    "args_test_batch_size = 1000\n",
    "args_epochs = 20\n",
    "args_lr = 0.001\n",
    "args_momentum = 0.9\n",
    "args_decay = 5e-4\n",
    "args_seed = 1\n",
    "args_log_interval = 2500\n",
    "args_no_cuda = False\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args_seed)\n",
    "if args_cuda:\n",
    "    torch.cuda.manual_seed(args_seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args_cuda else {}\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: define your network here \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0)\n",
    "        self.weight1 = self.conv1.weight.data.numpy()\n",
    "        self.features = nn.Sequential(\n",
    "            # 32 * 32 * 3, CIFAR\n",
    "            self.conv1,\n",
    "            # (32 - 5) / 1 + 1 = 28, 28 * 28 * 6\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # (28 - 2) / 2 + 1 = 14, 14 * 14 * 6\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            # 14 - 5 + 1 = 10, 10 * 10 * 16\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # 5 * 5 * 16\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.6),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        conv_features = self.features(x)\n",
    "        flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        fc = self.fc_layers(flatten)\n",
    "        #probas = F.softmax(logits, dim=1)\n",
    "        return fc\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_decay)\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list  = []\n",
    "valid_acc_list  = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # use cross_entropy here, since there is no softmax function in my last layer\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "        \n",
    "        loss_sum += loss.data\n",
    "        total += 1\n",
    "        \n",
    "    train_loss_list.append(loss_sum / total)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # preserve the accuracy for plot and comparison\n",
    "    test_loss_list.append(test_loss)\n",
    "    valid_acc_list.append(100. * correct / len(test_loader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, args_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.323506\n",
      "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 2.142912\n",
      "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 2.745064\n",
      "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 1.093693\n",
      "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 0.813302\n",
      "\n",
      "Test set: Average loss: 1.4207, Accuracy: 4883/10000 (49%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.992471\n",
      "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 1.608712\n",
      "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 1.194683\n",
      "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.376128\n",
      "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 1.102659\n",
      "\n",
      "Test set: Average loss: 1.3868, Accuracy: 5143/10000 (51%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.767755\n",
      "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 1.568396\n",
      "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 0.533004\n",
      "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.075071\n",
      "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 0.812473\n",
      "\n",
      "Test set: Average loss: 1.3111, Accuracy: 5327/10000 (53%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.459106\n",
      "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 0.764019\n",
      "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 0.789062\n",
      "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 1.127551\n",
      "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 2.175224\n",
      "\n",
      "Test set: Average loss: 1.1799, Accuracy: 5817/10000 (58%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.039875\n",
      "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 1.265098\n",
      "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 1.553946\n",
      "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 1.072184\n",
      "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 0.716355\n",
      "\n",
      "Test set: Average loss: 1.1270, Accuracy: 6011/10000 (60%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weight initialization\n",
    "\n",
    "\n",
    "# Training settings\n",
    "args_batch_size = 64\n",
    "args_test_batch_size = 1000\n",
    "args_epochs = 20\n",
    "args_lr = 0.001\n",
    "args_momentum = 0.9\n",
    "args_decay = 5e-4\n",
    "args_seed = 1\n",
    "args_log_interval = 2500\n",
    "args_no_cuda = False\n",
    "args_cuda = not args_no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args_seed)\n",
    "if args_cuda:\n",
    "    torch.cuda.manual_seed(args_seed)\n",
    "\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args_cuda else {}\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: define your network here \n",
    "            \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight)\n",
    "        # for visualize the filters in the first conv layer\n",
    "        self.weight1 = self.conv1.weight.data.numpy()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "#         self.features = nn.Sequential(\n",
    "#             # 32 * 32 * 3, CIFAR\n",
    "#             self.conv1,\n",
    "#             # (32 - 5) / 1 + 1 = 28, 28 * 28 * 6\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # (28 - 2) / 2 + 1 = 14, 14 * 14 * 6\n",
    "#             nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "#             # 14 - 5 + 1 = 10, 10 * 10 * 16\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             # 5 * 5 * 16\n",
    "#         )  \n",
    "        \n",
    "#         self.fc_layers = nn.Sequential(\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(16 * 5 * 5, 120),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(0.6),\n",
    "#             nn.Linear(120, 84),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(84, num_classes),\n",
    "#         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        # conv_features = self.features(x)\n",
    "        # flatten = conv_features.view(conv_features.size(0), -1)\n",
    "        # fc = self.fc_layers(flatten)\n",
    "        # probas = F.softmax(logits, dim=1)\n",
    "        # return fc\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_decay)\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list  = []\n",
    "valid_acc_list  = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # use cross_entropy here, since there is no softmax function in my last layer\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data))\n",
    "        \n",
    "        loss_sum += loss.data\n",
    "        total += 1\n",
    "        \n",
    "    train_loss_list.append(loss_sum / total)\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target).data\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # preserve the accuracy for plot and comparison\n",
    "    test_loss_list.append(test_loss)\n",
    "    valid_acc_list.append(100. * correct / len(test_loader.dataset))\n",
    "\n",
    "\n",
    "for epoch in range(1, args_epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12243eb50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the filters learned in the first convolutional layer\n",
    "\n",
    "weight1 = model.conv1.weight.detach().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(231)\n",
    "plt.imshow(weight1[0, ...].T)\n",
    "plt.subplot(232)\n",
    "plt.imshow(weight1[1, ...].T)\n",
    "plt.subplot(233)\n",
    "plt.imshow(weight1[2, ...].T)\n",
    "plt.subplot(234)\n",
    "plt.imshow(weight1[3, ...].T)\n",
    "plt.subplot(235)\n",
    "plt.imshow(weight1[4, ...].T)\n",
    "plt.subplot(236)\n",
    "plt.imshow(weight1[5, ...].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(np.arange(1, args_epochs+1), train_acc_list, label='Training')\n",
    "#plt.plot(np.arange(1, args_epochs+1), valid_acc_list, label='Validation')\n",
    "\n",
    "#plt.plot(np.arange(1, args_epochs+1), test_loss_list, label='Validation')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7",
   "language": "python",
   "name": "python-3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
